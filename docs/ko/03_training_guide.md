# Libra í•™ìŠµ ê°€ì´ë“œ (Stage 1 & Stage 2)

## ëª©ì°¨
- [2-Stage í•™ìŠµ ì „ëµ ê°œìš”](#2-stage-í•™ìŠµ-ì „ëµ-ê°œìš”)
- [Stage 1: Visual Feature Alignment](#stage-1-visual-feature-alignment)
- [Stage 2: Downstream Task Fine-tuning](#stage-2-downstream-task-fine-tuning)
- [í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ ìƒì„¸](#í•™ìŠµ-ë©”ì»¤ë‹ˆì¦˜-ìƒì„¸)
- [ì™„ì „í•œ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸](#ì™„ì „í•œ-í•™ìŠµ-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## 2-Stage í•™ìŠµ ì „ëµ ê°œìš”

### ì „ì²´ ë¹„êµí‘œ

| í•­ëª© | **Stage 1: Pretrain** | **Stage 2: Finetune** |
|------|----------------------|----------------------|
| **í•œê¸€ëª…** | Visual Feature Alignment | Downstream Task Fine-tuning |
| **ëª©ì ** | TACê°€ Vision â†’ LLM ë³€í™˜ í•™ìŠµ | LLMì´ Report Generation í•™ìŠµ |
| **ì…ë ¥ ë°ì´í„°** | `libra_alignment_train.json` (780 MB) | `libra_findings_section_train.json` (159 MB) |
| **ë°ì´í„° ë‚´ìš©** | RRG + VQA í˜¼í•© (ë‹¤ì–‘í•œ task) | Findings sectionë§Œ (íŠ¹ì • task) |
| **í•™ìŠµ ëŒ€ìƒ** | ğŸ”¥ **TACë§Œ** | ğŸ”¥ **LLMë§Œ (LoRA)** |
| **Frozen** | Vision Encoder + LLM | Vision Encoder + TAC |
| **Epochs** | 1 | 3 |
| **í•™ìŠµ ì‹œê°„** | ~385ì‹œê°„ (16ì¼) | ~213ì‹œê°„ (9ì¼) |
| **Learning Rate** | 2e-5 | 2e-5 |
| **ì¶œë ¥ë¬¼** | `mm_tac_projector.bin` | `adapter_model.bin` (LoRA) |
| **ìŠ¤í¬ë¦½íŠ¸** | `pretrain.sh` | `finetune_lora.sh` |

---

## Stage 1: Visual Feature Alignment

### ëª©ì 

```
[RAD-DINO features] â†’ [TAC í•™ìŠµ ì¤‘] â†’ [Meditron ì…ë ¥ í˜•ì‹]
                          â†‘
                    ì´ ë³€í™˜ì„ ë°°ìš´ë‹¤!
```

Vision encoderì˜ ì¶œë ¥(ì´ë¯¸ì§€ íŠ¹ì§•)ì„ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

---

### ë°ì´í„°ì…‹

**íŒŒì¼**: `libra_alignment_train.json` (780 MB)

**êµ¬ì„±**:
- Radiology Report Generation (RRG)
- Visual Question Answering (VQA)
  - MIMIC-Diff-VQA
  - MIMIC-Ext-MIMIC-CXR-VQA
- ëª¨ë“  ì„¹ì…˜ í¬í•¨ (Findings, Impression, Indication, History ë“±)

**ëª©ì **: TACê°€ ë‹¤ì–‘í•œ ì‹œê°ì  ì´í•´ ëŠ¥ë ¥ í•™ìŠµ

**ë‹¤ìš´ë¡œë“œ**:
```bash
# Google Drive
wget https://drive.google.com/file/d/1AIT1b3eRXgJFp3FJmHci3haTunK1NTMA/
```

---

### í•™ìŠµ ì„¤ì •

**ìŠ¤í¬ë¦½íŠ¸**: `scripts/pretrain.sh`

```bash
###############################################################################
# Stage 1 Hyperparameters
###############################################################################

# â•â•â• ë°ì´í„° â•â•â•
TRAIN_DATA="./data/libra_alignment_train.json"
VAL_DATA="./data/libra_alignment_valid.json"
IMG_FOLDER="./data/mimic-cxr-jpg/2.0.0"

# â•â•â• ëª¨ë¸ êµ¬ì„± â•â•â•
MODEL_VERSION="epfl-llm/meditron-7b"
VISION_TOWER="microsoft/rad-dino"
PROMPT_VERSION="libra_v1"

# â•â•â• í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° â•â•â•
NUM_EPOCHS=1                    # 1 epochë§Œ
TRAIN_BSZ=16                    # Per-device batch size
EVAL_BSZ=4
GRAD_ACC_STEPS=1
LR=2e-5                         # Learning rate
WEIGHT_DECAY=0.
WARMUP_RATIO=0.03               # 3% warmup
LR_SCHEDULER="cosine"
MAX_LENGTH=2048

# â•â•â• TAC í•™ìŠµ í”Œë˜ê·¸ â•â•â•
--freeze_backbone True          # â„ï¸ LLM frozen
--tune_mm_mlp_adapter True      # ğŸ”¥ TAC trainable
--freeze_mm_mlp_adapter False   # ğŸ”¥ TAC trainable
--mm_projector_type TAC
--mm_vision_select_layer all    # All 12 layers

# â•â•â• ìµœì í™” ì„¤ì • â•â•â•
--bf16 True
--gradient_checkpointing True
--deepspeed ./scripts/zero2.json
```

---

### í•™ìŠµë˜ëŠ” íŒŒë¼ë¯¸í„°

| ë¸”ë¡ | ìƒíƒœ | íŒŒë¼ë¯¸í„° ìˆ˜ |
|------|------|-----------|
| Vision Encoder (RAD-DINO) | â„ï¸ Frozen | 87M |
| **TAC (mm_projector)** | ğŸ”¥ **Trainable** | **~50M** |
| LLM (Meditron-7B) | â„ï¸ Frozen | 7B |

**ì½”ë“œ**: `train.py:1702-1705`

```python
if model_args.tune_mm_mlp_adapter:
    model.requires_grad_(False)  # ëª¨ë“  íŒŒë¼ë¯¸í„° freeze
    for p in model.get_model().mm_projector.parameters():
        p.requires_grad = True   # TACë§Œ í•™ìŠµ
```

---

### ì¶œë ¥ë¬¼

```
./checkpoints/libra-v1.0-7b-pretrain/
â”œâ”€â”€ mm_tac_projector.bin        # â­ TAC weights (í•µì‹¬!)
â”œâ”€â”€ config.json                 # ëª¨ë¸ ì„¤ì •
â””â”€â”€ training_state.json         # í•™ìŠµ ìƒíƒœ
```

**ì‚¬ìš© ë°©ë²•**:
```bash
# Stage 2ì—ì„œ ë¡œë“œ
--model_name_or_path ./checkpoints/libra-v1.0-7b-pretrain

# ë˜ëŠ” pretrained projector ì‚¬ìš©
--model_name_or_path epfl-llm/meditron-7b
--pretrain_mm_mlp_adapter ./mm_tac_projector.bin
```

---

### í•™ìŠµ ì‹œê°„

**A6000 1ê°œ ê¸°ì¤€**: ~385 hours (16ì¼)

**ì´ìœ **:
- ëŒ€ê·œëª¨ ë°ì´í„° (780 MB)
- TACì˜ ë³µì¡í•œ attention êµ¬ì¡°
- 1 epochë§Œ (overfitting ë°©ì§€)

---

## Stage 2: Downstream Task Fine-tuning

### ëª©ì 

```
[ì´ë¯¸ì§€] â†’ [TAC ê³ ì •] â†’ [LLM LoRA í•™ìŠµ] â†’ [Radiology Report]
                              â†‘
                    Report ìƒì„±ì„ ë°°ìš´ë‹¤!
```

LLMì´ X-ray ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì •í™•í•œ Radiology Reportë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

---

### ë°ì´í„°ì…‹

**íŒŒì¼**: `libra_findings_section_train.json` (159 MB)

**êµ¬ì„±**:
- Findings section generationë§Œ ì§‘ì¤‘
- MIMIC-CXRì˜ íŠ¹ì • ì„¹ì…˜
- Temporal comparison í¬í•¨

**ëª©ì **: íŠ¹ì • downstream taskì— íŠ¹í™”

**ë‹¤ìš´ë¡œë“œ**:
```bash
wget https://drive.google.com/file/d/1rJ3G4uiHlzK_P6ZBUbAi-cDaWV-o6fcz/
```

---

### í•™ìŠµ ì„¤ì •

**ìŠ¤í¬ë¦½íŠ¸**: `scripts/finetune_lora.sh`

```bash
###############################################################################
# Stage 2 Hyperparameters
###############################################################################

# â•â•â• ë°ì´í„° â•â•â•
TRAIN_DATA="./data/libra_findings_section_train.json"
VAL_DATA="./data/libra_findings_section_valid.json"
IMG_FOLDER="./data/mimic-cxr-jpg/2.0.0"

# â•â•â• ëª¨ë¸ êµ¬ì„± â•â•â•
MODEL_VERSION="./checkpoints/libra-v1.0-7b-pretrain"  # Stage 1 ì¶œë ¥
VISION_TOWER="microsoft/rad-dino"
PROMPT_VERSION="libra_v1"

# â•â•â• LoRA í•˜ì´í¼íŒŒë¼ë¯¸í„° â­ â•â•â•
LORA_R=128                      # LoRA rank
LORA_ALPHA=256                  # LoRA alpha (scaling=2.0)
LORA_DROPOUT=0.05
MM_PROJECTOR_LR=2e-5            # TAC learning rate (optional)

# â•â•â• í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° â•â•â•
NUM_EPOCHS=3                    # 3 epochs
TRAIN_BSZ=16
EVAL_BSZ=4
GRAD_ACC_STEPS=1
LR=2e-5                         # LoRA learning rate
WEIGHT_DECAY=0.
WARMUP_RATIO=0.03
LR_SCHEDULER="cosine"
MAX_LENGTH=2048

# â•â•â• LoRA í•™ìŠµ í”Œë˜ê·¸ â•â•â•
--lora_enable True              # ğŸ”¥ LoRA í™œì„±í™”
--lora_r ${LORA_R}
--lora_alpha ${LORA_ALPHA}
--freeze_backbone True          # â„ï¸ LLM backbone frozen
--tune_mm_mlp_adapter False     # â„ï¸ TAC frozen
--freeze_mm_mlp_adapter True    # â„ï¸ TAC frozen

# â•â•â• ìµœì í™” ì„¤ì • â•â•â•
--bf16 True
--gradient_checkpointing True
--deepspeed ./scripts/zero3.json  # Zero-3 (ë” ë©”ëª¨ë¦¬ íš¨ìœ¨)
```

---

### í•™ìŠµë˜ëŠ” íŒŒë¼ë¯¸í„°

| ë¸”ë¡ | ìƒíƒœ | íŒŒë¼ë¯¸í„° ìˆ˜ |
|------|------|-----------|
| Vision Encoder | â„ï¸ Frozen | 87M |
| TAC | â„ï¸ Frozen | 50M |
| LLM Backbone | â„ï¸ Frozen | 7B |
| **LoRA Adapters** | ğŸ”¥ **Trainable** | **~224M** |

**LoRA ì ìš© ìœ„ì¹˜**:
- LLMì˜ ëª¨ë“  Linear layers
- q_proj, k_proj, v_proj, o_proj (Attention)
- gate_proj, up_proj, down_proj (MLP)

---

### ì¶œë ¥ë¬¼

```
./checkpoints/libra-v1.0-7b-lora/
â”œâ”€â”€ adapter_model.bin           # â­ LoRA weights (224M)
â”œâ”€â”€ adapter_config.json         # LoRA config
â”œâ”€â”€ non_lora_trainables.bin     # TAC (ë³µì‚¬ë³¸)
â”œâ”€â”€ config.json
â””â”€â”€ training_state.json
```

**ì‚¬ìš© ë°©ë²•**:
```python
from libra.eval import libra_eval

result = libra_eval(
    model_path="./checkpoints/libra-v1.0-7b-lora",
    model_base="epfl-llm/meditron-7b",
    image_file=["current.jpg", "prior.jpg"],
    query="Describe the findings..."
)
```

---

### í•™ìŠµ ì‹œê°„

**A6000 1ê°œ ê¸°ì¤€**: ~213 hours (9ì¼)

**ì´ìœ **:
- ì‘ì€ ë°ì´í„°ì…‹ (159 MB)
- í•˜ì§€ë§Œ 3 epochs
- LoRAë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

---

## í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ ìƒì„¸

### ì™œ 2-Stageê°€ í•„ìš”í•œê°€?

#### í•œ ë²ˆì— í•™ìŠµí•˜ë©´ ì•ˆë˜ë‚˜ìš”?

**ë¬¸ì œì **:

1. **Catastrophic Forgetting**
   - TAC + LLM ë™ì‹œ í•™ìŠµ ì‹œ Vision feature ë³€í™”ì— LLMì´ ì ì‘ ëª»í•¨

2. **í•™ìŠµ ë¶ˆì•ˆì •**
   - ë‘ ëª¨ë“ˆì˜ í•™ìŠµ ì†ë„ê°€ ë‹¬ë¼ ìˆ˜ë ´ ì–´ë ¤ì›€

3. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ëª¨ë“  gradient ë™ì‹œ ê³„ì‚° ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±

#### 2-Stageì˜ ì¥ì 

```
Stage 1: TACë§Œ ì§‘ì¤‘ í•™ìŠµ
         â†“
    ì•ˆì •ì ì¸ feature ìƒì„±
         â†“
Stage 2: LLMì´ ê³ ì •ëœ featureë¡œ í•™ìŠµ
         â†“
    ì•ˆì •ì  ìˆ˜ë ´ + ë†’ì€ ì„±ëŠ¥
```

---

### Learning Rate ì„¤ì •

**Multi-LR ì‹œìŠ¤í…œ** (libra_trainer.py:165-194)

```python
# Stage 1
optimizer_grouped_parameters = [
    {
        "params": [...],  # TAC weights
        "weight_decay": 0.0,
        "lr": 2e-5  # TAC LR
    }
]

# Stage 2
optimizer_grouped_parameters = [
    {
        "params": [...],  # LoRA weights
        "weight_decay": 0.0,
        "lr": 2e-5  # LoRA LR
    },
    {
        "params": [...],  # mm_projector (optional)
        "weight_decay": 0.0,
        "lr": 2e-6  # TAC LR (ë” ë‚®ê²Œ)
    }
]
```

---

### Stageë³„ í•™ìŠµ ë¹„êµí‘œ

| ì¸¡ë©´ | Stage 1 | Stage 2 |
|------|---------|---------|
| **Batch Size** | 16 | 16 |
| **Global Batch** | 16 | 16 |
| **Epochs** | 1 | 3 |
| **LR** | 2e-5 | 2e-5 |
| **Scheduler** | Cosine | Cosine |
| **Warmup** | 3% | 3% |
| **Weight Decay** | 0 | 0 |
| **Max Length** | 2048 | 2048 |
| **DeepSpeed** | Zero-2 | Zero-3 |
| **Precision** | BF16 | BF16 |

---

## ì™„ì „í•œ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Step 0: í™˜ê²½ ì¤€ë¹„

```bash
# 1. ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/X-iZhang/Libra.git
cd Libra

# 2. í™˜ê²½ ì„¤ì¹˜
conda create -n libra python=3.10 -y
conda activate libra
pip install -e ".[train,eval]"
pip install flash-attn --no-build-isolation

# 3. CUDA í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"
```

---

### Step 1: ë°ì´í„° ì¤€ë¹„

```bash
# 1. MIMIC-CXR ë‹¤ìš´ë¡œë“œ
# https://physionet.org/content/mimic-cxr-jpg/2.0.0/

# 2. Libra annotation ë‹¤ìš´ë¡œë“œ
mkdir -p ./data
cd ./data

# Stage 1 ë°ì´í„°
wget https://drive.google.com/file/d/1AIT1b3eRXgJFp3FJmHci3haTunK1NTMA/
wget https://drive.google.com/file/d/1nvbUoDmw7j4HgXwZWiiACIhvZ6BvR2LX/

# Stage 2 ë°ì´í„°
wget https://drive.google.com/file/d/1rJ3G4uiHlzK_P6ZBUbAi-cDaWV-o6fcz/
wget https://drive.google.com/file/d/1IYwQS23veOU5SXWGYiTyq9VHUwkVESfD/

# êµ¬ì¡° í™•ì¸
tree -L 2
# ./data/
# â”œâ”€â”€ physionet.org/files/mimic-cxr-jpg/2.0.0/
# â”œâ”€â”€ libra_alignment_train.json
# â”œâ”€â”€ libra_alignment_valid.json
# â”œâ”€â”€ libra_findings_section_train.json
# â””â”€â”€ libra_findings_section_valid.json
```

---

### Step 2: Stage 1 í•™ìŠµ (TAC)

```bash
# 1. pretrain.sh ìˆ˜ì •
vim scripts/pretrain.sh

# ìˆ˜ì •í•  ë¶€ë¶„:
# - TRAIN_DATA ê²½ë¡œ
# - VAL_DATA ê²½ë¡œ
# - IMG_FOLDER ê²½ë¡œ
# - OUTPUT_DIR ê²½ë¡œ

# 2. í•™ìŠµ ì‹œì‘
bash scripts/pretrain.sh

# 3. ëª¨ë‹ˆí„°ë§ (ë³„ë„ í„°ë¯¸ë„)
watch -n 1 nvidia-smi
tail -f checkpoints/libra-v1.0-7b-pretrain/training.log

# 4. ê²°ê³¼ í™•ì¸ (385ì‹œê°„ í›„)
ls ./checkpoints/libra-v1.0-7b-pretrain/
# mm_tac_projector.bin  â† ì´ê²ƒì´ í•µì‹¬!
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**:
- A6000 1ê°œ: 16ì¼
- H100 1ê°œ: 2.7ì¼

---

### Step 3: Stage 2 í•™ìŠµ (LoRA)

```bash
# 1. finetune_lora.sh ìˆ˜ì •
vim scripts/finetune_lora.sh

# ìˆ˜ì •í•  ë¶€ë¶„:
# - MODEL_VERSION="./checkpoints/libra-v1.0-7b-pretrain"
# - TRAIN_DATA ê²½ë¡œ
# - VAL_DATA ê²½ë¡œ
# - OUTPUT_DIR ê²½ë¡œ

# 2. í•™ìŠµ ì‹œì‘
bash scripts/finetune_lora.sh

# 3. ê²°ê³¼ í™•ì¸ (213ì‹œê°„ í›„)
ls ./checkpoints/libra-v1.0-7b-lora/
# adapter_model.bin        â† LoRA weights
# adapter_config.json
# non_lora_trainables.bin  â† TAC (ë³µì‚¬ë³¸)
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**:
- A6000 1ê°œ: 9ì¼
- H100 1ê°œ: 1.5ì¼

---

### Step 4: Inference í…ŒìŠ¤íŠ¸

```python
from libra.eval import libra_eval

# í…ŒìŠ¤íŠ¸
result = libra_eval(
    model_path="./checkpoints/libra-v1.0-7b-lora",
    model_base="epfl-llm/meditron-7b",
    image_file=["./examples/current.jpg", "./examples/prior.jpg"],
    query="Describe the findings in comparison to the prior image.",
    conv_mode="libra_v1"
)

print(result)
```

---

### Step 5: í‰ê°€

```bash
# 1. Generate predictions
python -m libra.eval.run_libra \
    --model-path ./checkpoints/libra-v1.0-7b-lora \
    --model-base epfl-llm/meditron-7b \
    --question-file ./data/libra_findings_section_eval.jsonl \
    --image-folder ./data/mimic-cxr-jpg/2.0.0 \
    --answers-file ./results/answer-file.jsonl

# 2. Evaluate
python libra/eval/radiology_report.py \
    --references ./data/libra_findings_section_eval.jsonl \
    --predictions ./results/answer-file.jsonl
```

---

## Stage ê±´ë„ˆë›°ê¸° ì˜µì…˜

### Stage 1 ê±´ë„ˆë›°ê¸° (ê³µê°œ Projector ì‚¬ìš©)

```bash
# 1. Pretrained TAC ë‹¤ìš´ë¡œë“œ
wget https://huggingface.co/X-iZhang/libra-v1.0-7b/resolve/main/mm_tac_projector.bin

# 2. Stage 2 ë°”ë¡œ ì‹¤í–‰
# finetune_lora.shì— ì¶”ê°€:
--model_name_or_path epfl-llm/meditron-7b \
--pretrain_mm_mlp_adapter ./mm_tac_projector.bin \
```

**ì ˆì•½ ì‹œê°„**: 16ì¼! (Stage 1 ìƒëµ)

---

### Stage 2 ê±´ë„ˆë›°ê¸° (ê³µê°œ LoRA ì‚¬ìš©)

```bash
# 1. Pretrained LoRA ë‹¤ìš´ë¡œë“œ
git lfs install
git clone https://huggingface.co/X-iZhang/libra-v1.0-7b

# 2. ë°”ë¡œ Inference
python -m libra.eval.run_libra \
    --model-path ./libra-v1.0-7b \
    --model-base epfl-llm/meditron-7b \
    ...
```

**ì ˆì•½ ì‹œê°„**: 9ì¼! (Stage 2 ìƒëµ)

---

## ìš”ì•½

| ë‹¨ê³„ | ì‹œê°„ | GPU | ëˆ„ì  | ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ |
|------|------|-----|------|-------------|
| Stage 1 | 385h (16ì¼) | A6000 x1 | 16ì¼ | âœ… (ê³µê°œ TAC ì‚¬ìš©) |
| Stage 2 | 213h (9ì¼) | A6000 x1 | **25ì¼** | âœ… (ê³µê°œ LoRA ì‚¬ìš©) |

**í•µì‹¬**:
- Stage 1: TACê°€ vision-language alignment í•™ìŠµ
- Stage 2: LLMì´ report generation í•™ìŠµ
- ë…ë¦½ì ì´ì§€ë§Œ ìˆœì°¨ì 
- ê³µê°œ weightsë¡œ ê° stage ê±´ë„ˆë›°ê¸° ê°€ëŠ¥

---

## ì°¸ê³  ìë£Œ

- **ë…¼ë¬¸**: [Libra (ACL 2025)](https://arxiv.org/abs/2411.19378)
- **ì½”ë“œ**: [GitHub](https://github.com/X-iZhang/Libra)
- **ëª¨ë¸**: [HuggingFace](https://huggingface.co/X-iZhang/libra-v1.0-7b)
- **ë°ì´í„°**: Google Drive (README ì°¸ì¡°)
